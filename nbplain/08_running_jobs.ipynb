{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bridal-option",
   "metadata": {},
   "source": [
    "# Running a job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-designer",
   "metadata": {},
   "source": [
    "Below are example submission scripts for several different codes.\n",
    "\n",
    "These examples copy the run data from the submission directory in `/campaign/` area to `$BURSTBUFFER` before the run, and copy any files back to `/campaign/` afterwards. The script then cleans up by removing the `working_directory` in the `$BURSTBUFFER` area (this will be done automatically, but is perhaps a good habit to get into for furture developments in terms of storage were this may not be the case).\n",
    "\n",
    "\n",
    "Obviously there are an infinite number of ways to structure the logic in your submission scripts in order to handle the data transfer between `/campaign/` and `$BURSTBUFFER`.\n",
    "\n",
    "The following examples can be adapted to your own needs. They should be submitted from the `/campaign/` storage area, they will create a temporary working directory in `$BURSTBUFFER/$SLURM_JOB_ID` and copy the contents of the submission folder over to the working directory. After the run it copies the contents of the working directory in `$BURSTBUFFER/SLURM_JOB_ID` back to the submission directory in `/campaign/`. It then cleans up the working directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2c018",
   "metadata": {},
   "source": [
    "## Account code\n",
    "\n",
    "The account code used in your run script `#SBATCH --account=ACCOUNT_CODE` should match the resource allocation you wish to run your job against. If you don't know your resource allocation code check the research computing account managemnet portal at `rcam.bath.ac.uk` (you need to be on the University's VPN All traffic), or ask your account administrator. \n",
    "\n",
    "## QOS\n",
    "\n",
    "The quality of service (QOS) set in your run script with e.g. `#SBATCH --qos=spot-hbv3-120` should match the partition name you are submitting to. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-benefit",
   "metadata": {},
   "source": [
    "## Openfoam\n",
    "\n",
    "We will run an example job using the OpenFoam 7 module for \n",
    "\n",
    "`OpenFoam_hbv3/gcc_9.2.0/openmpi_4.1.0/v7`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-zoning",
   "metadata": {},
   "source": [
    "Let's load the module:\n",
    "```bash\n",
    "module load OpenFoam_hbv3/gcc_9.2.0/openmpi_4.1.0/v7\n",
    "```\n",
    "\n",
    "Source the OpenFoam bashrc:\n",
    "\n",
    "```bash\n",
    "source $foamDotFile```\n",
    "\n",
    "Lets switch to our scratch space:\n",
    "\n",
    "```bash\n",
    "cd $SCRATCH\n",
    "```\n",
    "\n",
    "\n",
    "And copy over the run files:\n",
    "``` bash\n",
    "cp -r $WM_PROJECT_DIR/tutorials/multiphase/interFoam/laminar/damBreak ./```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-darwin",
   "metadata": {},
   "source": [
    "An example run script:\n",
    "    \n",
    "```bash\n",
    "#!/bin/bash\n",
    "#SBATCH --account=prj3_phase1\n",
    "#SBATCH --job-name=JOB_NAME\n",
    "#SBATCH --output=JOB_NAME.%j.o\n",
    "#SBATCH --error=JOB_NAME.%j.e\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=120\n",
    "#SBATCH --partition=spot-hbv3-120\n",
    "#SBATCH --qos=spot-hbv3-120\n",
    "#SBATCH --time=04:00:00\n",
    "\n",
    "module purge\n",
    "module load OpenFoam_hbv3/gcc_9.2.0/openmpi_4.1.0/v7\n",
    "\n",
    "# As an example of moving input data from /campaign\n",
    "# to scratch we will create and mirror the submit\n",
    "# directory structure on scratch:\n",
    "\n",
    "campaigndir=$(pwd)\n",
    "\n",
    "echo $campaigndir | if grep -q campaign; then \n",
    "    # Copy any inputs required to the work directory:\n",
    "    # excluding and files with a JOB_NAME prefix, so your\n",
    "    # output and error files don't get over written on the copy back\n",
    "    rsync -aP --exclude=JOB_NAME.* $campaigndir/* $BURSTBUFFER\n",
    "    cd $BURSTBUFFER;\n",
    "    echo  \"Work directory\" $BURSTBUFFER ;\n",
    "    \n",
    "    # source the foamDotFile and do the run\n",
    "    . $foamDotFile\n",
    "    ./Allrun\n",
    "\n",
    "    # Copy back results.\n",
    "    srun cp -Rf $BURSTBUFFER/*  $campaigndir/\n",
    "    #Clean up scratch\n",
    "    rm -rf $BURSTBUFFER\n",
    "else\n",
    "     echo \"Not submitting from campaign. Check your submission script.\"\n",
    "     exit 1;\n",
    "fi\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-lying",
   "metadata": {},
   "source": [
    "Lets switch into the folder \n",
    "```bash\n",
    "cd damBreak\n",
    "```\n",
    "\n",
    "And after copying the above runscript into `run_job.slm` lets submit the job:\n",
    "\n",
    "```bash\n",
    "sbatch run_job.slm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-delivery",
   "metadata": {},
   "source": [
    "### Interactive job\n",
    "\n",
    "It is also possible to obtain a compute node and work interactively. \n",
    "\n",
    "Issuing the following command in the terminal will request a spot-hbv3-120 compute instance for 6 hours:\n",
    "\n",
    "```\n",
    "srun --partition spot-hbv3-120 --nodes 1  --account prj4_phase1  --qos spot-hbv3-120 --job-name \"interactive\" --cpus-per-task 120 --time 6:00:00 --pty bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e093085",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
