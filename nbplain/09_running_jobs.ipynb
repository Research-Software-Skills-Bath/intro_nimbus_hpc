{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are example submission scripts for Nimbus to illustrate the typical workflow2.\n",
    "\n",
    "The following example can be adapted to your own needs. Typically they will be submitted from the `/campaign/` storage area.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slurm directives\n",
    "\n",
    "Every line that starts with a `#SBATCH` is a directive for `slurm` this is where we tell slurm the resources we want for our job. \n",
    "\n",
    "`#SBATCH --account=` tells slurm what account you wish to run against. The account code used in your run script `#SBATCH --account=ACCOUNT_CODE` should match the resource allocation you wish to run your job against. If you don't know your resource allocation code check the research computing account managemnet portal at `rcam.bath.ac.uk` (you need to be on the University's VPN All traffic), or ask your account administrator. or use the command `sacctmgr show associations user=userid --parsable2`. This command will also tell you the limits on the account, and what QOS (and partitions) you have access to. \n",
    "\n",
    "`#SBATCH --job-name=` gives the job a name, which you can identify in the queue - you can call the job whatever you want that helps you to identify it. \n",
    "\n",
    "`#SBATCH --partition=` tells slurm what partition to put the job on. \n",
    "\n",
    "`#SBATCH --qos=` tells slurm what Quality of Service you wish to run with. The QOS is simply a way for admins to apply rules to the resources you can access, and the priority of the job. For Nimbus HPC systems the qos will match the partition name - and **remember** if you don't include it you will get an error. Nimbus is set so that the value of --qos has to agree exactly with the value of --partition!\n",
    "\n",
    "`#SBATCH --time=` tells slurm how long you wish to run the job for, with several acceptable formats:  \"minutes\", \"minutes:seconds\", \"hours:minutes:seconds\", \"days-hours\", \"days-hours:minutes\" and \"days-hours:minutes:seconds\" e.g. `1-01:20:00` will request a runtime of 25 hours and 20 mins. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting a simple job\n",
    "\n",
    "Create a text file named `output.txt` with the following in your campaign folder. \n",
    "\n",
    "```bash\n",
    "this is my nimbus test\n",
    "```\n",
    "\n",
    "Hint:  You can check what accounts you have access to with `sacctmgr`, and you will also have access to a folder /campaign/account_code (not case sensitive - the campaign folder will be in capitals).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a python file called `test_script.py` in your campaign directory containing the following:\n",
    "\n",
    "```\n",
    "with open('output.txt', 'w') as f:\n",
    "    f.write('this is my nimbus test')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a slurm script defining the parameters of the run called `run_python_script.slm` which contains the following:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#SBATCH --account=RA-code\n",
    "#SBATCH --job-name=JOB_NAME\n",
    "#SBATCH --output=%x.%j.o\n",
    "#SBATCH --error=%x.%j.e\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --partition=spot-fsv2-1\n",
    "#SBATCH --qos=spot-fsv2-1\n",
    "#SBATCH --time=00:01:00\n",
    "\n",
    "#Identify node correctly\n",
    "source /apps/build/easy_build/scripts/id_instance.sh\n",
    "source /apps/build/easy_build/scripts/setup_modules.sh\n",
    "\n",
    "module purge\n",
    "module load Python/3.9.5-GCCcore-10.3.0\n",
    "\n",
    "# Do Run\n",
    "python3 test_script.py\n",
    "\n",
    "```\n",
    "\n",
    "Finally to submit the script, in the command line run:\n",
    "\n",
    "`sbatch run_python_job.slm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLPOLY\n",
    "\n",
    "We will run an example job to run a DLPOLY simulation, using the `DL_POLY_Classic/1.10-foss-2020b` module on the spot_fsv2_16 instance including the `--oversubscribe` tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example run script - create a file named `run_job.slm` with the following contents (remembering to replace the account code with that of your resource allocation):\n",
    "    \n",
    "```bash\n",
    "#!/bin/bash\n",
    "#SBATCH --account=BA-CH2FAM-001\n",
    "#SBATCH --job-name=dlp\n",
    "#SBATCH --output=dlp.%j.o\n",
    "#SBATCH --error=dlp.%j.e\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=16\n",
    "#SBATCH --partition=spot-fsv2-16\n",
    "#SBATCH --qos=spot-fsv2-16\n",
    "#SBATCH --time=06:00:00\n",
    "\n",
    "#Identify node correctly\n",
    "source /apps/build/easy_build/scripts/id_instance.sh\n",
    "source /apps/build/easy_build/scripts/setup_modules.sh\n",
    "\n",
    "#Purge modules and load required modules\n",
    "module purge\n",
    "module load DL_POLY_Classic/1.10-foss-2020b\n",
    "\n",
    "#Run job\n",
    "mpirun --oversubscribe -np 16 --host $(hostname):16 DLPOLY.X\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And to run the job issue the following command in the terminal:\n",
    "\n",
    "```bash\n",
    "sbatch run_job.slm\n",
    "```\n",
    "\n",
    "**Note**: The `source` commands in the slurm script helps the node to recognise its 'identity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive job\n",
    "\n",
    "It is also possible to obtain a compute node and work interactively. \n",
    "\n",
    "Issuing the following command in the terminal will request a spot-hbv3-120 compute instance for 6 hours:\n",
    "\n",
    "```\n",
    "srun --partition spot-hbv3-120 --nodes 1  --account prj4_phase1  --qos spot-hbv3-120 --job-name \"interactive\" --cpus-per-task 120 --time 6:00:00 --pty bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
